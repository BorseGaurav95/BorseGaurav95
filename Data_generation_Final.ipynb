{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNFGp4j0WkKLQUeDRPxcBG4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BorseGaurav95/BorseGaurav95/blob/main/Data_generation_Final.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7BNwn3b-drJa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5849356b-fc25-437c-f981-4d61f4a25a1c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: faker in /usr/local/lib/python3.8/dist-packages (15.3.4)\n",
            "Requirement already satisfied: python-dateutil>=2.4 in /usr/local/lib/python3.8/dist-packages (from faker) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.8/dist-packages (from python-dateutil>=2.4->faker) (1.15.0)\n"
          ]
        }
      ],
      "source": [
        "pip install faker\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sdv"
      ],
      "metadata": {
        "id": "lWKL0h8F3y-F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "from google.cloud import bigquery\n",
        "data = {}\n",
        "fake = Faker()\n",
        "from shapely import Point, LineString\n",
        "\n",
        "import json\n",
        "\n",
        "class Object:\n",
        "    def toJSON(self):\n",
        "        return json.dumps(self, default=lambda o: o.__dict__, \n",
        "            sort_keys=True, indent=4)\n",
        "\n",
        "import shapely.geometry\n",
        "import shapely.wkt\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "'/content/wwbq-cartos1.json')\n",
        "\n",
        "project_id = 'wwbq-cartos1'\n",
        "table_id = \"wwbq-cartos1.Test_DG.d\"\n",
        "\n",
        "client = bigquery.Client(credentials= credentials,project=project_id)\n",
        "\n",
        "query_job = client.query(\"\"\"\n",
        "   SELECT column_name \n",
        "   FROM wwbq-cartos1.Test_DG.INFORMATION_SCHEMA.COLUMNS\n",
        "    where table_name = 'd'\n",
        "    \"\"\")\n",
        "\n",
        "results = query_job.result()\n",
        "\n",
        "col_name=[]\n",
        "for row in results:\n",
        "  col_name.append(row.column_name) \n",
        "\n",
        "col_name\n",
        "arr_len=len(col_name)\n",
        "for i in range(10):\n",
        "    for j in range(arr_len):  \n",
        "       col_name1 = col_name[j]\n",
        "       if((col_name1=='latitude') or (col_name1=='longitude')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = float(eval(col_data))\n",
        "       else:   \n",
        "         \n",
        "          \n",
        "          data[col_name1.title()] = str(Point(\n",
        "          [float(fake.latitude()), float(fake.latitude())]))\n",
        "                                                        \n",
        "       rows_to_insert = [data]\n",
        "       #print(rows_to_insert)          \n",
        "    \n",
        "       \n",
        "    errors = client.insert_rows_json(table_id, rows_to_insert)  # Make an API request.\n",
        "    if errors == []:\n",
        "      print(\"1 new row has been added.\")\n",
        "    else:\n",
        "      print(\"Encountered errors while inserting rows: {}\".format(errors))\n"
      ],
      "metadata": {
        "id": "U3ma_WuLAEhq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#V0\n"
      ],
      "metadata": {
        "id": "VERyejgsudGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random as r\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "from faker import Faker\n",
        "from google.cloud import bigquery\n",
        "from tqdm import tqdm\n",
        "\n",
        "data = {}\n",
        "fake = Faker()\n",
        "count = 0\n",
        "\n",
        "input_table=input(\"Enter BigQuery table name = \")\n",
        "n_record=int(input(\"Enter record count = \"))\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "'/content/wwbq-cartos1.json')\n",
        "\n",
        "project_id = 'wwbq-cartos1'\n",
        "table_id = \"wwbq-cartos1.Test_DG.\"+input_table\n",
        "\n",
        "client = bigquery.Client(credentials= credentials,project=project_id)\n",
        "\n",
        "query_job = client.query(\"\"\"\n",
        "   SELECT column_name \n",
        "   FROM wwbq-cartos1.Test_DG.INFORMATION_SCHEMA.COLUMNS\n",
        "    where table_name = '\"\"\" + input_table + \"\"\"'\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "results = query_job.result()\n",
        "\n",
        "col_name=[]\n",
        "for row in results:\n",
        "  col_name.append(row.column_name) \n",
        "\n",
        "col_name\n",
        "arr_len=len(col_name)\n",
        "Faker.seed(99)\n",
        "for i in range(n_record):\n",
        "    for j in range(arr_len):  \n",
        "       col_name1 = col_name[j]\n",
        "  \n",
        "       if((col_name1=='latitude') or (col_name1=='longitude')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = float(eval(col_data))\n",
        "       elif((col_name1=='phone_number')):\n",
        "          # col_data = \"fake.\"+col_name1+'()'\n",
        "          # data[col_name1.title()] = eval(col_data)\n",
        "          ph_no=[]\n",
        "          ph_no.append(r.randint(6, 9))  \n",
        "          for i in range(1, 10):\n",
        "              ph_no.append(r.randint(0, 9))\n",
        "          res = str(\"\".join(map(str, ph_no)))\n",
        "          data[col_name1.title()] = res\n",
        "       elif((col_name1=='zip')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          byte_ch = base64.b64encode(bytes(str(eval(col_data)), 'utf-8'))\n",
        "          data[col_name1.title()] = byte_ch.decode('utf-8')\n",
        "       elif((col_name1=='date_time')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          str_date=str(eval(col_data))\n",
        "          data[col_name1.title()] = str_date\n",
        "          #data[col_name1.title()] = parser.parse(str_date)\n",
        "          #print(data[col_name1.title()])\n",
        "          #data[col_name1.title()] =  datetime.strptime(str_date, '%')\n",
        "       elif((col_name1=='pydecimal')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          big_num=str(eval(col_data))\n",
        "          data[col_name1.title()] = big_num\n",
        "       elif((col_name1=='latlng')):\n",
        "          data[col_name1.title()] = str(\n",
        "          [float(fake.latitude()), float(fake.latitude())])\n",
        "         \n",
        "       else:   \n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = eval(col_data)\n",
        "       rows_to_insert = [data]\n",
        "    # print(rows_to_insert)\n",
        "       \n",
        "    errors = client.insert_rows_json(table_id, rows_to_insert)  # Make an API request.\n",
        "    count=count+1\n",
        "    if errors == []:\n",
        "      pass\n",
        "    else:\n",
        "      print(\"Encountered errors while inserting rows: {}\".format(errors))\n",
        "      break\n",
        "for i in tqdm(range(count), desc=\"Loading...\"):\n",
        "      pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CMzcLItGebO6",
        "outputId": "d951b94a-0914-456f-ee62-7cb3cf37c866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter BigQuery table name = geo_data\n",
            "Enter record count = 10\n",
            "Encountered errors while inserting rows: [{'index': 0, 'errors': [{'reason': 'invalid', 'location': 'latlng', 'debugInfo': '', 'message': \"Cannot convert value [18.4420385, 12.207507] to GEOGRAPHY: Unexpected '[' at position 0.\"}]}]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading...: 100%|██████████| 1/1 [00:00<00:00, 739.48it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#V1"
      ],
      "metadata": {
        "id": "0MOvZdX38Vx6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random as r\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "from faker import Faker\n",
        "from google.cloud import bigquery\n",
        "from tqdm import tqdm\n",
        "from google.oauth2 import service_account\n",
        "from shapely.geometry import Point, LineString, Polygon\n",
        "\n",
        "\n",
        "\n",
        "json_file_path=\"\"\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "json_file_path=input(\"Enter GCP Service account Json key file path = \") \n",
        "print(\"-------------------------------------------------------------------\")\n",
        "input_table=input(\"Enter BigQuery table name (Project_id.Dataset_name.Table_name) = \")\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "n_record=int(input(\"Enter record count = \"))\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "json_file_path)\n",
        "\n",
        "tb_name=input_table.split(\".\")\n",
        "project_id = tb_name[0]\n",
        "dataset_id = tb_name[1]\n",
        "table_id = tb_name[2]\n",
        "\n",
        "client = bigquery.Client(credentials= credentials,project=project_id)\n",
        "\n",
        "query_job = client.query(\"\"\"\n",
        "   SELECT column_name \n",
        "   FROM \"\"\" + project_id + \"\"\".\"\"\" + dataset_id + \"\"\".INFORMATION_SCHEMA.COLUMNS\n",
        "    where table_name = '\"\"\" + table_id + \"\"\"'\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "results = query_job.result()\n",
        "\n",
        "col_name=[]\n",
        "\n",
        "for row in results:\n",
        "  col_name.append(row.column_name) \n",
        "\n",
        "arr_len=len(col_name)\n",
        "\n",
        "data = {}\n",
        "count = 0\n",
        "\n",
        "fake = Faker()\n",
        "Faker.seed(99)\n",
        "\n",
        "for i in range(n_record):\n",
        "    for j in range(arr_len):  \n",
        "       col_name1 = col_name[j]\n",
        "  \n",
        "       if((col_name1=='latitude') or (col_name1=='longitude')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = float(eval(col_data))\n",
        "       elif((col_name1=='phone_number')):\n",
        "          # col_data = \"fake.\"+col_name1+'()'\n",
        "          # data[col_name1.title()] = eval(col_data)\n",
        "          ph_no=[]\n",
        "          ph_no.append(r.randint(6, 9))  \n",
        "          for i in range(1, 10):\n",
        "              ph_no.append(r.randint(0, 9))\n",
        "          res = str(\"\".join(map(str, ph_no)))\n",
        "          data[col_name1.title()] = res\n",
        "       elif((col_name1=='zip')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          byte_ch = base64.b64encode(bytes(str(eval(col_data)), 'utf-8'))\n",
        "          data[col_name1.title()] = byte_ch.decode('utf-8')\n",
        "       elif((col_name1=='date_time')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          str_date=str(eval(col_data))\n",
        "          data[col_name1.title()] = str_date\n",
        "          #data[col_name1.title()] = parser.parse(str_date)\n",
        "          #print(data[col_name1.title()])\n",
        "          #data[col_name1.title()] =  datetime.strptime(str_date, '%')\n",
        "       elif((col_name1=='pydecimal')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          big_num=str(eval(col_data))\n",
        "          data[col_name1.title()] = big_num\n",
        "       elif((col_name1=='latlng')):\n",
        "          data[col_name1.title()] = str(Point(\n",
        "          [float(fake.longitude()), float(fake.latitude())]))\n",
        "       elif((col_name1=='big_num')):\n",
        "          data[col_name1.title()] = r.uniform(-5.7896044618658097711785492504343953926634992332820282019728792003956564819968E+38,5.7896044618658097711785492504343953926634992332820282019728792003956564819968E+38)\n",
        "       elif((col_name1=='record_data')):\n",
        "          data[col_name1.title()] = record = {'name': str(fake.name()), 'age': r.randint(1, 99), 'gender':r.choice(['male','female'])}\n",
        "\n",
        "       else:   \n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = eval(col_data)\n",
        "       rows_to_insert = [data]\n",
        "    # print(rows_to_insert)\n",
        "       \n",
        "    errors = client.insert_rows_json(input_table, rows_to_insert)  # Make an API request.\n",
        "    count=count+1\n",
        "    if errors == []:\n",
        "      pass\n",
        "    else:\n",
        "      print(\"Encountered errors while inserting rows: {}\".format(errors))\n",
        "      break\n",
        "for i in tqdm(range(count), desc=\"Loading...\"):\n",
        "      pass\n"
      ],
      "metadata": {
        "id": "Eg-gBSjN8aDQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fcf43d6d-d75b-4a7d-8d29-9c41214b2d6d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n",
            "Enter GCP Service account Json key file path = /content/wwbq-cartos1.json\n",
            "-------------------------------------------------------------------\n",
            "Enter BigQuery table name (Project_id.Dataset_name.Table_name) = wwbq-cartos1.Test_DG.b\n",
            "-------------------------------------------------------------------\n",
            "Enter record count = 10\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading...: 100%|██████████| 10/10 [00:00<00:00, 79588.31it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#V2"
      ],
      "metadata": {
        "id": "RCBV22Niwm0g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2rpqkrD2MMHv",
        "outputId": "af413fad-31c1-42aa-9774-027d476e090d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'name': 'John', 'age': 30, 'gender': 'male'}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import random as r\n",
        "import base64\n",
        "from datetime import datetime\n",
        "from dateutil import parser\n",
        "from faker import Faker\n",
        "from google.cloud import bigquery\n",
        "from tqdm import tqdm\n",
        "from google.oauth2 import service_account\n",
        "from shapely.geometry import Point\n",
        "\n",
        "\n",
        "\n",
        "json_file_path=\"\"\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "json_file_path=input(\"Enter GCP Service account Json key file path = \") \n",
        "print(\"-------------------------------------------------------------------\")\n",
        "input_table=input(\"Enter BigQuery table name (Project_id.Dataset_name.Table_name) = \")\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "n_record=int(input(\"Enter record count = \"))\n",
        "print(\"-------------------------------------------------------------------\")\n",
        "\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "json_file_path)\n",
        "\n",
        "tb_name=input_table.split(\".\")\n",
        "project_id = tb_name[0]\n",
        "dataset_id = tb_name[1]\n",
        "table_id = tb_name[2]\n",
        "\n",
        "client = bigquery.Client(credentials= credentials,project=project_id)\n",
        "\n",
        "query_job = client.query(\"\"\"\n",
        "   SELECT column_name \n",
        "   FROM \"\"\" + project_id + \"\"\".\"\"\" + dataset_id + \"\"\".INFORMATION_SCHEMA.COLUMNS\n",
        "    where table_name = '\"\"\" + table_id + \"\"\"'\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "results = query_job.result()\n",
        "\n",
        "col_name=[]\n",
        "\n",
        "for row in results:\n",
        "  col_name.append(row.column_name) \n",
        "\n",
        "arr_len=len(col_name)\n",
        "\n",
        "data = {}\n",
        "count = 0\n",
        "\n",
        "fake = Faker()\n",
        "Faker.seed(99)\n",
        "\n",
        "for i in range(n_record):\n",
        "    for j in range(arr_len):  \n",
        "       col_name1 = col_name[j]\n",
        "  \n",
        "       if((col_name1=='latitude') or (col_name1=='longitude')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = float(eval(col_data))\n",
        "       elif((col_name1=='phone_number')):\n",
        "          # col_data = \"fake.\"+col_name1+'()'\n",
        "          # data[col_name1.title()] = eval(col_data)\n",
        "          ph_no=[]\n",
        "          ph_no.append(r.randint(6, 9))  \n",
        "          for i in range(1, 10):\n",
        "              ph_no.append(r.randint(0, 9))\n",
        "          res = str(\"\".join(map(str, ph_no)))\n",
        "          data[col_name1.title()] = res\n",
        "       elif((col_name1=='zip')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          byte_ch = base64.b64encode(bytes(str(eval(col_data)), 'utf-8'))\n",
        "          data[col_name1.title()] = byte_ch.decode('utf-8')\n",
        "       elif((col_name1=='date_time')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          str_date=str(eval(col_data))\n",
        "          data[col_name1.title()] = str_date\n",
        "          #data[col_name1.title()] = parser.parse(str_date)\n",
        "          #print(data[col_name1.title()])\n",
        "          #data[col_name1.title()] =  datetime.strptime(str_date, '%')\n",
        "       elif((col_name1=='pydecimal')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          big_num=str(eval(col_data))\n",
        "          data[col_name1.title()] = big_num\n",
        "       elif((col_name1=='latlng')):\n",
        "          data[col_name1.title()] = str(Point(\n",
        "          [float(fake.longitude()), float(fake.latitude())]))\n",
        "       elif((col_name1=='big_num')):\n",
        "          data[col_name1.title()] = r.uniform(-5.7896044618658097711785492504343953926634992332820282019728792003956564819968E+38,5.7896044618658097711785492504343953926634992332820282019728792003956564819968E+38)\n",
        "       elif((col_name1=='record_data')):\n",
        "          data[col_name1.title()] = record = {'name': str(fake.name()), 'age': r.randint(1, 99), 'gender':r.choice(['male','female'])}\n",
        "\n",
        "       else:   \n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = eval(col_data)\n",
        "       rows_to_insert = [data]\n",
        "    # print(rows_to_insert)\n",
        "       \n",
        "    errors = client.insert_rows_json(input_table, rows_to_insert)  # Make an API request.\n",
        "    count=count+1\n",
        "    if errors == []:\n",
        "      pass\n",
        "    else:\n",
        "      print(\"Encountered errors while inserting rows: {}\".format(errors))\n",
        "      break\n",
        "for i in tqdm(range(count), desc=\"Loading...\"):\n",
        "      pass\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9e373bae-279b-41cc-b49c-a60dda9dfc15",
        "id": "1rU79njfUygA"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------------------------------------------------------------\n",
            "Enter GCP Service account Json key file path = /content/wwbq-cartos1.json\n",
            "-------------------------------------------------------------------\n",
            "Enter BigQuery table name (Project_id.Dataset_name.Table_name) = wwbq-cartos1.Test_DG.time\n",
            "-------------------------------------------------------------------\n",
            "Enter record count = 10\n",
            "-------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading...: 100%|██████████| 10/10 [00:00<00:00, 6892.86it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wwbq-cartos1.Test_DG.geo_data\n",
        "wwbq-cartos1.Test_DG.b\n",
        "wwbq-cartos1.Test_DG.time"
      ],
      "metadata": {
        "id": "x1Kah-07J0To"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from faker import Faker\n",
        "import pandas as pd\n",
        "from google.cloud import bigquery\n",
        "from tqdm import tqdm\n",
        "import sdv \n",
        "\n",
        "data = {}\n",
        "fake = Faker()\n",
        "count = 0\n",
        "\n",
        "input_table=input(\"Enter BigQuery table name = \")\n",
        "#n_record=int(input(\"Enter record count = \"))\n",
        "\n",
        "from google.oauth2 import service_account\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "'/content/wwbq-cartos1.json')\n",
        "\n",
        "project_id = 'wwbq-cartos1'\n",
        "table_id = \"wwbq-cartos1.Test_DG.\"+input_table\n",
        "\n",
        "client = bigquery.Client(credentials= credentials,project=project_id)\n",
        "\n",
        "query_job = client.query(\"\"\"\n",
        "   SELECT column_name \n",
        "   FROM wwbq-cartos1.Test_DG.INFORMATION_SCHEMA.COLUMNS\n",
        "    where table_name = '\"\"\" + input_table + \"\"\"'\n",
        "    \"\"\")\n",
        "\n",
        "\n",
        "results = query_job.result()\n",
        "\n",
        "col_name=[]\n",
        "for row in results:\n",
        "  col_name.append(row.column_name) \n",
        "\n",
        "col_name\n",
        "arr_len=len(col_name)\n",
        "for i in range(100):\n",
        "    for j in range(arr_len):  \n",
        "       col_name1 = col_name[j]\n",
        "       if((col_name1=='latitude') or (col_name1=='longitude')):\n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = float(eval(col_data))\n",
        "       else:   \n",
        "          col_data = \"fake.\"+col_name1+'()'\n",
        "          data[col_name1.title()] = eval(col_data)\n",
        "       rows_to_insert = [data]\n",
        "    # print(rows_to_insert)\n",
        "       \n",
        "    errors = client.insert_rows_json(table_id, rows_to_insert)  # Make an API request.\n",
        "    count=count+1\n",
        "    if errors == []:\n",
        "      pass\n",
        "    else:\n",
        "      print(\"Encountered errors while inserting rows: {}\".format(errors))\n",
        "      break\n",
        "for i in tqdm(range(count), desc=\"Loading...\"):\n",
        "      pass\n",
        "\n",
        "\n",
        "\n",
        "target_data = client.query(\"\"\"\n",
        "   SELECT *\n",
        "   FROM `wwbq-cartos1.Test_DG.\"\"\" + input_table + \"\"\"`\n",
        "   \"\"\").to_dataframe()\n",
        "\n",
        "target_data.to_csv('/test_date.csv',header=True, index=False)\n",
        "\n",
        "sdv_input_data = pd.read_csv('/test_date.csv')\n",
        "\n",
        "\n",
        "from sdv.tabular import CopulaGAN\n",
        "\n",
        "model = CopulaGAN()\n",
        "model.fit(sdv_input_data)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YZF7_Pl23Z60",
        "outputId": "59bc11ed-622c-4f68-d217-55f2b6b2e99e"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Enter BigQuery table name = AB\n",
            "Enter record count = 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Loading...: 100%|██████████| 10/10 [00:00<00:00, 71697.50it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample = model.sample(10000000)\n",
        "sample"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 423
        },
        "id": "b3eUTd862qFg",
        "outputId": "0323ef0c-16ef-44b2-9e5f-bb3a9ea6a128"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     name                                            address\n",
              "0         Cynthia Jackson    3234 Jackson Place\\nSouth Carolynside, PW 21642\n",
              "1              Kyle Smith       372 Nicholas Way\\nLake Andreamouth, VI 34534\n",
              "2             Mary Gamble  552 Russell Isle Apt. 834\\nMcdowellmouth, NM 5...\n",
              "3        Benjamin Burgess  0416 Jimenez Streets Apt. 599\\nNorth Jonton, V...\n",
              "4             Joyce Novak                   762 Lee Run\\nWest Ryan, OR 32416\n",
              "...                   ...                                                ...\n",
              "9999995      Victoria Orr       372 Nicholas Way\\nLake Andreamouth, VI 34534\n",
              "9999996        David Mann       372 Nicholas Way\\nLake Andreamouth, VI 34534\n",
              "9999997    Richard Miller                   PSC 7524, Box 5439\\nAPO AP 36140\n",
              "9999998        Terry Odom                   PSC 7524, Box 5439\\nAPO AP 36140\n",
              "9999999        Terry Odom         58795 Connie Overpass\\nNew Bryan, PW 01518\n",
              "\n",
              "[10000000 rows x 2 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d638666b-b98f-426d-a6c8-dbdb2c9179a6\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>name</th>\n",
              "      <th>address</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Cynthia Jackson</td>\n",
              "      <td>3234 Jackson Place\\nSouth Carolynside, PW 21642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Kyle Smith</td>\n",
              "      <td>372 Nicholas Way\\nLake Andreamouth, VI 34534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Mary Gamble</td>\n",
              "      <td>552 Russell Isle Apt. 834\\nMcdowellmouth, NM 5...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Benjamin Burgess</td>\n",
              "      <td>0416 Jimenez Streets Apt. 599\\nNorth Jonton, V...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Joyce Novak</td>\n",
              "      <td>762 Lee Run\\nWest Ryan, OR 32416</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999995</th>\n",
              "      <td>Victoria Orr</td>\n",
              "      <td>372 Nicholas Way\\nLake Andreamouth, VI 34534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999996</th>\n",
              "      <td>David Mann</td>\n",
              "      <td>372 Nicholas Way\\nLake Andreamouth, VI 34534</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999997</th>\n",
              "      <td>Richard Miller</td>\n",
              "      <td>PSC 7524, Box 5439\\nAPO AP 36140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999998</th>\n",
              "      <td>Terry Odom</td>\n",
              "      <td>PSC 7524, Box 5439\\nAPO AP 36140</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9999999</th>\n",
              "      <td>Terry Odom</td>\n",
              "      <td>58795 Connie Overpass\\nNew Bryan, PW 01518</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>10000000 rows × 2 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d638666b-b98f-426d-a6c8-dbdb2c9179a6')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-d638666b-b98f-426d-a6c8-dbdb2c9179a6 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-d638666b-b98f-426d-a6c8-dbdb2c9179a6');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample.to_csv('/date_gen.csv')"
      ],
      "metadata": {
        "id": "IswKyGdW2gyb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "652b2222-4cbf-4177-ac44-45228771994a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-75-408eb839b658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msample\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/date_gen.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'sample' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  \n",
        "ph_no = []\n",
        "  \n",
        "\n",
        "print(res)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fl3H-VDsunVs",
        "outputId": "bbe78e23-69eb-4245-f26d-abf854942590"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "7160820099\n"
          ]
        }
      ]
    }
  ]
}